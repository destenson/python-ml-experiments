{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning this may resize any files in C:\\Users\\deste\\Pictures\\Saved Pictures\\pics\\\n",
      "Finding similar images...\n",
      "Checking 238 images...\n",
      "Resizing all 10 images\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'ANTIALIAS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m     create_video_from_images(most_similar_images, output_video_path, fps)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 75\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 69\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m first_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(most_similar_images[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     68\u001b[0m target_size \u001b[38;5;241m=\u001b[39m first_image\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m---> 69\u001b[0m \u001b[43mresize_images_to_same_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmost_similar_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Step 3: Create video from images\u001b[39;00m\n\u001b[0;32m     72\u001b[0m create_video_from_images(most_similar_images, output_video_path, fps)\n",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m, in \u001b[0;36mresize_images_to_same_size\u001b[1;34m(images, size)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[0;32m     38\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\n\u001b[1;32m---> 39\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(size, \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANTIALIAS\u001b[49m)\n\u001b[0;32m     40\u001b[0m     img\u001b[38;5;241m.\u001b[39msave(img_path)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'ANTIALIAS'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops\n",
    "\n",
    "def compute_image_difference(img1, img2):\n",
    "    \"\"\"Compute the root mean square difference between two images.\"\"\"\n",
    "    # print(\"Computing image difference...\")\n",
    "    diff = ImageChops.difference(img1, img2)\n",
    "    h = diff.histogram()\n",
    "    sq = (value * ((idx % 256) ** 2) for idx, value in enumerate(h))\n",
    "    sum_of_squares = sum(sq)\n",
    "    rms = (sum_of_squares / float(img1.size[0] * img1.size[1])) ** 0.5\n",
    "    # print(f\"Image difference was {rms:.3f}\")\n",
    "    return rms\n",
    "\n",
    "def find_similar_images(directory):\n",
    "    \"\"\"Find the most similar images in the directory.\"\"\"\n",
    "    print(\"Finding similar images...\")\n",
    "    images = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.png')]\n",
    "    similar_pairs = []\n",
    "    \n",
    "    print(f\"Checking {len(images)} images...\")\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i + 1, len(images)):\n",
    "            img1 = Image.open(images[i])\n",
    "            img2 = Image.open(images[j])\n",
    "            diff = compute_image_difference(img1, img2)\n",
    "            similar_pairs.append((images[i], images[j], diff))\n",
    "    \n",
    "    similar_pairs.sort(key=lambda x: x[2])\n",
    "    return similar_pairs\n",
    "\n",
    "def resize_images_to_same_size(images, size):\n",
    "    \"\"\"Resize images to the same size.\"\"\"\n",
    "    print(f\"Resizing all {len(images)} images\")\n",
    "    for img_path in images:\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize(size, Image.ANTIALIAS)\n",
    "        img.save(img_path)\n",
    "\n",
    "def create_video_from_images(images, output_video_path, fps=1):\n",
    "    \"\"\"Create a video from a list of images.\"\"\"\n",
    "    print(\"Creating video from images...\")\n",
    "    frame = cv2.imread(images[0])\n",
    "    height, width, layers = frame.shape\n",
    "    video = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    print(\"Writing frames...\")\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(image))\n",
    "\n",
    "    print(\"Writing video complete.\")\n",
    "    video.release()\n",
    "\n",
    "def main():\n",
    "    image_directory = 'C:\\\\Users\\\\deste\\\\Pictures\\\\Saved Pictures\\\\pics\\\\'\n",
    "    print(f\"Warning this may resize any files in {image_directory}\")\n",
    "    output_video_path = 'output_video.mp4'\n",
    "    fps = 2  # Frames per second\n",
    "\n",
    "    # Step 1: Find similar images\n",
    "    similar_images = find_similar_images(image_directory)\n",
    "    most_similar_images = [pair[0] for pair in similar_images[:10]]  # Select top 10 similar images\n",
    "\n",
    "    # Step 2: Resize images to the same size\n",
    "    first_image = Image.open(most_similar_images[0])\n",
    "    target_size = first_image.size\n",
    "    resize_images_to_same_size(most_similar_images, target_size)\n",
    "\n",
    "    # Step 3: Create video from images\n",
    "    create_video_from_images(most_similar_images, output_video_path, fps)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning this may resize any files in C:\\Users\\deste\\Pictures\\Saved Pictures\\pics\\\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115b2db1f0504292a3d60a4a765837ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m     create_video_from_frames(all_frames, output_video_path, fps)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 49\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m all_frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(images) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 49\u001b[0m     img1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlatent_dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     50\u001b[0m     img2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode_image(images[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m), device, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlatent_dist\u001b[38;5;241m.\u001b[39msample()\n\u001b[0;32m     51\u001b[0m     intermediate_frames \u001b[38;5;241m=\u001b[39m generate_intermediate_frames(img1, img2, model, num_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\deste\\repos\\kan\\.venv\\Lib\\site-packages\\diffusers\\pipelines\\stable_diffusion\\pipeline_stable_diffusion.py:485\u001b[0m, in \u001b[0;36mStableDiffusionPipeline.encode_image\u001b[1;34m(self, image, device, num_images_per_prompt, output_hidden_states)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, image, device, num_images_per_prompt, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 485\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m())\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    488\u001b[0m         image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_extractor(image, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mpixel_values\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "import cv2\n",
    "\n",
    "def load_images(image_paths):\n",
    "    return [Image.open(img_path) for img_path in image_paths]\n",
    "\n",
    "def generate_intermediate_frames(img1, img2, model, num_frames=10):\n",
    "    \"\"\"Generate intermediate frames using a diffusion model.\"\"\"\n",
    "    frames = []\n",
    "    for i in range(num_frames):\n",
    "        alpha = i / float(num_frames)\n",
    "        interpolated_latent = (1 - alpha) * img1 + alpha * img2\n",
    "        frame = model.decode(interpolated_latent)\n",
    "        frames.append(frame)\n",
    "    return frames\n",
    "\n",
    "def create_video_from_frames(frames, output_video_path, fps=20):\n",
    "    \"\"\"Create a video from a list of frames.\"\"\"\n",
    "    height, width, _ = frames[0].shape\n",
    "    video_writer = cv2.VideoWriter(output_video_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    for frame in frames:\n",
    "        video_writer.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
    "    video_writer.release()\n",
    "\n",
    "def main():\n",
    "    # Paths to input images\n",
    "    image_directory = 'C:\\\\Users\\\\deste\\\\Pictures\\\\Saved Pictures\\\\pics\\\\'\n",
    "    print(f\"Warning this may resize any files in {image_directory}\")\n",
    "    output_video_path = 'output_video.mp4'\n",
    "    fps = 20\n",
    "\n",
    "    # Load the diffusion model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\").to(device)\n",
    "    model.scheduler = DDIMScheduler.from_config(model.scheduler.config)\n",
    "\n",
    "    # Load images and find similar pairs\n",
    "    image_files = [os.path.join(image_directory, f) for f in os.listdir(image_directory) if f.endswith('.png')]\n",
    "    images = load_images(image_files)\n",
    "    \n",
    "    all_frames = []\n",
    "    for i in range(len(images) - 1):\n",
    "        img1 = model.encode_image(images[i].convert(\"RGB\"), device, 1).latent_dist.sample()\n",
    "        img2 = model.encode_image(images[i + 1].convert(\"RGB\"), device, 1).latent_dist.sample()\n",
    "        intermediate_frames = generate_intermediate_frames(img1, img2, model, num_frames=10)\n",
    "        all_frames.extend(intermediate_frames)\n",
    "    all_frames.append(images[-1])\n",
    "\n",
    "    # Create and save the video\n",
    "    create_video_from_frames(all_frames, output_video_path, fps)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
